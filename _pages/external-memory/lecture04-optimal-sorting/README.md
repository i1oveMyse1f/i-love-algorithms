---
layout: lecture
title:  "Оптимальность сортировки во внешней памяти"
author: i_love_myself
categories: [ external_memory, sorting ]
toc: true
---

## Теорема

<div markdown="1" class="alert alert-theorem">
Пусть в EM модели есть массив размера $N$, который нужно отсортировать, тогда существует алгоритм сортировки, время работы которого $O(\frac{N}{B} \log_{\frac{M}{B}} \frac{N}{B})$. Более того, если модель удовлетворяет **comparation assumption**, то быстрее нельзя.
</div>

Comparation assumption означает, что мы можем только сравнивать элементы массива, а не делать с ними произвольные операции (только сравнения и перестановки, аналогично нижней оценке на сортировки в RAM модели).

Вообще говоря, мы можем применить теорему об оптимальности решения задачи о перестановке к задаче сортировки, поскольку сортировка - это частный случай перестановки. Тогда, даже имея готовый массив сортированной перестановки, мы не сможем решить задачу быстрее $\Omega(\min(N, \frac{N}{B} \log_{\frac{M}{B}} \frac{N}{B}))$, но доказательство использовало indivisibility assumption, в нашем же случае мы докажем более сильную теорему для EM Comparation модели. Более того, в нашем варианте не будет случая сортировки за $\Omega(N)$, которая возможна в indivisible model!

## Доказательство

Алгоритм мы уже представили раньше - K-way merge sort. Основная часть - доказать нижнюю оценку.

Как и в доказательстве нижней оценки на сортировку в RAM модели, мы будем пользоваться деревом принятия решений, но с некоторыми изменениями под новую модель вычислений:

* Идея заключается в том, что каждая вершина дерева - это некоторая операция, доступная в нашей модели вычислений (в RAM модели это была операция сравнения двух элементов, в EM модели это будет чтение/запись блока из/в память)
* Каждая вершина-операция может иметь $T(v)$ детей - вариантов алгоритма в зависимости от операции и состояния (в RAM модели было возможно только два исхода у операции сравнения, теперь для новых операций исходов может быть больше, оценим их количество позже)
* Листья в дереве - это окончание алгоритма, они содержат информацию о решении задачи (например, финальную перестановку)
* Глубина дерева - это количество операций для решения задачи в худшем случае, иначе говоря мы хотим доказать, что глубина дерева хотя бы $\Omega(\frac{N}{B} \log_{\frac{M}{B}} \frac{N}{B})$.

**Шаг 1.** Без ограничения общности, пусть:

* $N$ делится на $B$
* входной массив состоит из $\frac{N}{B}$ блоков, каждый из которых уже осортирован (если нет, то сделаем нулевую итерацию, отсортирова блоки за $O(\frac{N}{B})$) - это никак не повлияет на оценку
* Все элементы во входном массиве различны
* Входной массив представляет из себя _перестановку_ размера $N$
* Все операции полезны, то есть они используются для получения выходного результата или полезного промежуточного

**Шаг 2.** Оценим количество листьев в дереве. Всего различных перестановок на $N$ элементах - $N!$, среди них только $\frac{N!}{(B!)^{\frac{N}{B}}}$ перестановок, у которых блоки размера $B$ отсортированы.

Для каждой различной возможной входной перестановки дерево должно содержать различный выходной результат, следовательно количество листьев хотя бы $\frac{N!}{(B!)^{\frac{N}{B}}}$

**Шаг 3.** Определим вершины в дереве и оценим их степень.

Без ограничения общности Internal Memory будет хранить $M$ элементов (или меньше) в отсортированном порядке. Это предположение допустимо, поскольку любая перестановка во внутренней памяти никак не учитывается при оценке времени работы алгоритма (оценивается только read/write).

Каждая вершина может либо прочитать новый блок из $B$ элементов из внешней памяти во внутренюю, либо записать его в обратную сторону, таким образом будут доступны две операции:

* ReadSort(u) - прочитать некоторый блок $u$ из External Memory и отсортировать его. В оперативной памяти после операции чтения будет не больше $M$ элементов, из них $B$ мы только что считали, то есть получили не больше $C_{M}^{B}$ вариантов, как могут быть расположены $B$ элементов из $M$
* WriteSort(B) - взять некоторый блок элементов из внутренней памяти и записать его в отсортированном порядке во внешнюю память. Мы можем записывать блоки в отсортированном порядке, поскольку если данный блок в будущем будет использован как входной, то будет автоматом отсортирован, либо если такой блок будет использован для выходной последовательности, то он обязан быть отсортирован. Вариантов записи для WriteSort тоже $C_{M}^{B}$ - мы лишь выбираем какие $B$ элементов из всей внутренней памяти размера $M$ будут записаны

Итого, каждая вершина может иметь не больше $C_{M}^{B}$ детей

**Шаг 4.** Оценим глубину дерева.

Пусть $H$ - глубина дерева, тогда на глубине $H$ мы получим не больше $(C_{M}^{B})^{H}$ листьев, то есть:

$$
(С_{M}^{B})^H \geq \frac{N!}{(B!)^{\frac{N}{B}}}
$$

Или, взяв логарифм:

$$
H \ln \left(C_M^B\right) \geq \ln n! - \frac{N}{B} \ln B!
$$

Далее повторим все шаги, что и в доказательстве нижней оценки на перстановку. Из формулы Стирлинга мы получим:

$$
n \ln n - n < \ln n! < n \ln n
$$

И, как следствие, опуская технические детали, $\ln C_n^k \geq k \ln \frac{n}{k} - n$.

Тогда левую часть без $H$ мы можем оценить снизу как:

$$ \ln \left(C_M^B\right) \geq B \ln \frac{M}{B} $$

А правую часть неравенства оценить сверху как:

$$
\frac{n!}{(B!)^{\frac{N}{B}}} \leq N \ln \frac{N}{B} + N \leq 2 N \ln \frac{N}{B}
$$

Таким образом мы получили неравенство:

$$
H \left(B \ln \frac{M}{B} \right) \geq 2 N \ln \frac{N}{B}
$$

Или

$$
H \geq \frac{2N \ln \frac{N}{B}}{B \ln \frac{M}{B}} = \Theta(\frac{N}{B} \log_{\frac{M}{B}} \frac{N}{B})
$$

То есть получили нижнюю оценку на $H$ в $\Omega(\frac{N}{B} \log_{\frac{M}{B}} \frac{N}{B})$ что и требовалось доказать.

## Задачи

1. **Невозможная сортировка**. В начале раздела мы показали, что lower bound на сортировку в indivisble model - это $\Omega(\min(N, \frac{N}{B} \log_{\frac{M}{B}} \frac{N}{B}))$. В частности, для случая $\ln n > B \ln \frac{M}{B}$ мы получим нижнюю оценку в $\Omega(N)$. Придумайте сортировку, работающую за такую асимптотику в indivisible model в предположении $\ln n > B \ln \frac{M}{B}$.

## Ссылки

1. [Конспекты](https://www.cse.cuhk.edu.hk/~taoyf/course/5020/fall14/notes/comp.pdf) профессора Yufei Tao из Chinese University of Hong Kong.
2. Оригинальная работа A. Aggarwal and J. S. Vitter. The input/output complexity of sorting and related problems.
CACM, 31(9):1116–1127, 1988.
3. Чуть более современное доказательство и ее расширение:  J. Erickson. Lower bounds for external algebraic decision trees. In SODA, pages 755–761, 2005.
